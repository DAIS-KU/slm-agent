import json
import os
import requests

def call_model_api_1(prompt_model, base_url, api_key, context, model_prompt):
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    messages = [
        {"role": "system", "content": model_prompt},
        {"role": "user", "content": f"Hints:\n{context}\n\n"}
    ]

    payload = {
        "model": prompt_model,
        "messages": messages,
        "max_tokens": 30000,
        "temperature": 0.7,
        "response_format": {"type": "json_object"}
    }

    response = requests.post(f"{base_url}/chat/completions", headers=headers, json=payload)
    return response.json()



if __name__ == '__main__':
    prompt_model = "gpt-4.1"
    api_key = os.environ.get("OPENAI_API_KEY")
    base_url = os.environ.get("OPENAI_BASE_URL") 

    input_file='your_hints_file_name'
    student_hints_file='your_student_hints_file'

    with open(input_file, 'r',encoding='utf-8') as f:
        data = f.read()

    k = 20

    model_1_prompt = (
    "Here are over 950 hints generated by LLMS, which are used to prompt code repair tasks. "
    "Please classify them. It can be divided into exception handling, type conversion, format issues or many other types. "
    f"After you have completed the classification, please sort these hints and select the {k} most important ones from them."
    )

    

    with open(student_hints_file, 'w') as file:
        response = call_model_api_1(
                prompt_model,
                base_url,
                api_key,
                data,
                model_1_prompt
            )

        re = response["choices"][0]["message"]["content"]
        file.write(f"{re}\n")





